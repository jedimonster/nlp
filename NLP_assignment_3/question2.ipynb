{
 "metadata": {
  "signature": "sha256:8f1cfc8dbf652e31916c7706b44189c2905fffc95c83480e6f78f522a1705305"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Question 2.1: Build a Parser"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we induce a PCFG and build a parser, we note that we must handle unknown words when we parse sentences. <br/>\n",
      "We do this by using POS tagging; before parsing a sentence, we replace each unknown word with its Part of Speech tag. As a result, the parser will have to know the Production (Penn-POS -> Universal-POS) where the Universal-POS is a terminal node replacing the original word in the sentence.<br/>\n",
      "To acheive this we define two methods:<br/>\n",
      "<ol>\n",
      "<li><b>get_parser -</b> gets a list of parsed trees, and returns (parser, pcfg) that include the POS rules mentioned above.</li>\n",
      "<li><b>pos_uncovered_tokens -</b> gets a sentence and a pcfg, and replaces each word not known in the pcfg by its part of speech (accoridng to the best tagger learned in Assignment 1)</li> \n",
      "</ol>\n",
      "As well as a mapping from Penn-POS tags to Universal-POS tags, <b>GRAMMAR_TO_POS</b>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import induce_pcfg, Nonterminal, ViterbiParser, Tree, Production, DefaultTagger\n",
      "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
      "from question1 import filter_tree, tree_to_productions, pcfg_cnf_learn\n",
      "\n",
      "from ass1 import *\n",
      "from nltk import UnigramTagger\n",
      "\n",
      "GRAMMAR_TO_POS = {\n",
      "    \"CC\": \"CONJ\",\n",
      "    \"CD\": \"NUM\",\n",
      "    \"DT\": \"DET\",\n",
      "    \"EX\": \"ADVERB\",\n",
      "    \"FW\": \"X\",\n",
      "    \"IN\": \"ADP\",\n",
      "    \"JJ\": \"ADJ\",\n",
      "    \"JJR\": \"ADJ\",\n",
      "    \"JJS\": \"ADJ\",\n",
      "    \"LS\": \".\",\n",
      "    \"MD\": \"VERB\",\n",
      "    \"NN\": \"NOUN\",\n",
      "    \"NNS\": \"NOUN\",\n",
      "    \"NNP\": \"NOUN\",\n",
      "    \"NNPS\": \"NOUN\",\n",
      "    \"PDT\": \"DET\",\n",
      "    \"POS\": \"PRON\",\n",
      "    \"PRP\": \"PRON\",\n",
      "    \"PRP$\": \"PRON\",\n",
      "    \"RB\": \"ADV\",\n",
      "    \"RBR\": \"ADV\",\n",
      "    \"RBS\": \"ADV\",\n",
      "    \"RP\": \"PRT\",\n",
      "    \"SYM\": \".\",\n",
      "    \"TO\": \"ADP\",\n",
      "    \"UH\": \"PRT\",\n",
      "    \"VB\": \"VERB\",\n",
      "    \"VBD\": \"VERB\",\n",
      "    \"VBG\": \"VERB\",\n",
      "    \"VBN\": \"VERB\",\n",
      "    \"VBP\": \"VERB\",\n",
      "    \"WDT\": \"DET\",\n",
      "    \"WP\": \"PRON\",\n",
      "    \"WP$\": \"PRON\",\n",
      "    \"WRB\": \"ADV\",\n",
      "}\n",
      "\n",
      "def get_pos_tagger():\n",
      "    all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "    train = all_words\n",
      "\n",
      "    u0 = UnigramTagger(train, backoff=DefaultTagger(\"NOUN\"))\n",
      "\n",
      "    return EntropyAffixTagger(train=train, cutoff=0.5, backoff=u0)\n",
      "\n",
      "\n",
      "tagger = get_pos_tagger()\n",
      "\n",
      "\n",
      "def pos_uncovered_tokens(test_sentence, training_pcfg):\n",
      "    pos = tagger.tag(test_sentence)\n",
      "    for i, token in enumerate(test_sentence):\n",
      "        if token not in training_pcfg._lexical_index:\n",
      "            test_sentence[i] = \"$\" + pos[i][1]\n",
      "\n",
      "    return test_sentence\n",
      "\n",
      "\n",
      "def get_parser(training_trees):\n",
      "    training_prods = sum([list(tree_to_productions(t)) for t in training_trees], list())\n",
      "    pos_rules = [Production(Nonterminal(lhs), [\"$\" + rhs]) for lhs, rhs in GRAMMAR_TO_POS.iteritems()]\n",
      "    training_prods += pos_rules\n",
      "    training_pcfg = induce_pcfg(Nonterminal(\"S\"), training_prods)\n",
      "    parser = ViterbiParser(training_pcfg)\n",
      "\n",
      "    return parser, training_pcfg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we test the annotating function on the first sentence in the test set (which already contains unknown words)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
      "trees = treebank.parsed_sents()\n",
      "eighty_perc = int(len(trees) * 0.8)\n",
      "training_trees = pcfg_cnf_learn(treebank, eighty_perc)\n",
      "test_trees = trees[eighty_perc:]\n",
      "parser, training_pcfg = get_parser(training_trees)\n",
      "\n",
      "test_tree = filter_tree(test_trees[0])\n",
      "test_sentence = test_tree.leaves()\n",
      "test_sentence = pos_uncovered_tokens(test_sentence, training_pcfg)\n",
      "\n",
      "print test_sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'The', u'latest', u'10-year', u'notes', u'were', u'quoted', u'at', u'100', u'22\\\\/32', u'to', u'yield', u'7.88', u'%', u'compared', u'with', u'100', '$NOUN', u'to', u'yield', u'7.90', u'%', u'.']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see it replaced unknown tokens by a part of speech, now let us try the parser:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(parser.parse(test_sentence))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ProbabilisticTree('S', [ProbabilisticTree('NP^<S>', [ProbabilisticTree('DT', ['The']) (p=0.08558352402745996), ProbabilisticTree('NP|<JJS>^<S>', [ProbabilisticTree('JJS', ['latest']) (p=0.0896551724137931), ProbabilisticTree('NP|<CD>^<S>', [ProbabilisticTree('CD', ['10-year']) (p=0.00039761431411530816), ProbabilisticTree('NNS', ['notes']) (p=0.005080268238162975)]) (p=6.733291236796521e-07)]) (p=6.707493186080824e-09)]) (p=8.485600949814815e-13), ProbabilisticTree('S|<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('VBD', ['were']) (p=0.06388526727509779), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VBN', ['quoted']) (p=0.0029708853238265003), ProbabilisticTree('VP|<PP>^<VP>', [ProbabilisticTree('PP^<VP>', [ProbabilisticTree('IN', ['at']) (p=0.04136099165190994), ProbabilisticTree('NP^<PP>', [ProbabilisticTree('QP^<NP>', [ProbabilisticTree('CD', ['100']) (p=0.012723658051689861), ProbabilisticTree('CD', ['22\\\\/32']) (p=0.00039761431411530816)]) (p=6.247077383094805e-07)]) (p=9.239646330539416e-09)]) (p=2.802338839278382e-10), ProbabilisticTree('S^<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('TO', ['to']) (p=0.9889277389277389), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VB', ['yield']) (p=0.010209042294603793), ProbabilisticTree('VP|<NP>^<VP>', [ProbabilisticTree('NP^<VP>', [ProbabilisticTree('NP^<NP>', [ProbabilisticTree('CD', ['7.88']) (p=0.0011928429423459245), ProbabilisticTree('NN', ['%']) (p=0.031950126631599456)]) (p=5.223329571072206e-07), ProbabilisticTree('VP^<NP>', [ProbabilisticTree('VBN', ['compared']) (p=0.0106951871657754), ProbabilisticTree('PP^<VP>', [ProbabilisticTree('IN', ['with']) (p=0.03933721224386542), ProbabilisticTree('NP^<PP>', [ProbabilisticTree('CD', ['100']) (p=0.012723658051689861), ProbabilisticTree('NNS', ['$NOUN']) (p=0.000203210729526519)]) (p=1.670753483225788e-08)]) (p=4.81937044161947e-10)]) (p=1.9845844707975737e-12)]) (p=1.7281469738403862e-20), ProbabilisticTree('S^<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('TO', ['to']) (p=0.9889277389277389), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VB', ['yield']) (p=0.010209042294603793), ProbabilisticTree('NP^<VP>', [ProbabilisticTree('CD', ['7.90']) (p=0.0011928429423459245), ProbabilisticTree('NN', ['%']) (p=0.031950126631599456)]) (p=5.143386176336758e-07)]) (p=8.888250145210049e-10)]) (p=1.2109687251364533e-10)]) (p=8.788173033847405e-11)]) (p=1.033816360825318e-31)]) (p=9.784692403897867e-35)]) (p=1.3331033997266647e-35)]) (p=9.674521815159225e-36)]) (p=2.223638782604839e-46)]) (p=1.7891726191982884e-50)]) (p=4.134050800170843e-53), ProbabilisticTree('.', ['.']) (p=0.9858611825192802)]) (p=3.780448885503274e-53)]) (p=1.599421990770694e-65)]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Question 2.2 - Metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from question2 import *\n",
      "%matplotlib inline\n",
      "ACCURACY_PER_DISTANCE = {}\n",
      "ACCURACY_PER_DISTANCE_LABELED = {}\n",
      "ACCURACY_PER_LABEL = {}\n",
      "\n",
      "\n",
      "def exist_same(con, cons_list):\n",
      "    for item in cons_list:\n",
      "        if (item[0].label().split('^')[0].split('|')[0] == con[0].label().split('^')[0].split('|')[0]) and (item[1] == con[1]) and (item[2] == con[2]):\n",
      "            return True\n",
      "#         if (item[0].label() == con[0].label()) and (item[1] == con[1]) and (item[2] == con[2]):\n",
      "#             return True\n",
      "\n",
      "    return False\n",
      "\n",
      "\n",
      "def calculate_index_metrics(origin_cons, guess_cons):\n",
      "    origin_indexes = set([(x[1], x[2]) for x in origin_cons])\n",
      "    guess_indexes = set([(x[1], x[2]) for x in guess_cons])\n",
      "    origin_len = len(origin_indexes)\n",
      "    guess_len = len(guess_indexes)\n",
      "    pre_count = 0\n",
      "    recall_count = 0\n",
      "    for item in guess_indexes:\n",
      "        distance = item[1]-item[0]+1\n",
      "        if distance not in ACCURACY_PER_DISTANCE:\n",
      "            ACCURACY_PER_DISTANCE[distance] = {'total': 0, 'matches': 0}\n",
      "\n",
      "        ACCURACY_PER_DISTANCE[distance]['total'] += 1\n",
      "\n",
      "        if item in origin_indexes:\n",
      "            ACCURACY_PER_DISTANCE[distance]['matches'] += 1\n",
      "            pre_count += 1\n",
      "\n",
      "    for item in origin_indexes:\n",
      "        if item in guess_indexes:\n",
      "            recall_count += 1\n",
      "\n",
      "    recall = float(recall_count)/float(origin_len)\n",
      "    precision = float(pre_count)/float(guess_len)\n",
      "    f_measure = 2*(recall*precision)/(recall + precision)\n",
      "\n",
      "    return precision, recall, f_measure\n",
      "\n",
      "\n",
      "def calculate_joint_metrics(origin_cons, guess_cons):\n",
      "    origin_cons = list(origin_cons)\n",
      "    guess_cons = list(guess_cons)\n",
      "    origin_len = len(list(origin_cons))\n",
      "    guess_len = len(list(guess_cons))\n",
      "\n",
      "    pre_count = 0\n",
      "    recall_count = 0\n",
      "    # calculate precision\n",
      "    for item in guess_cons:\n",
      "        distance = item[2]-item[1]+1\n",
      "        label = item[0].label().split('^')[0].split('|')[0]\n",
      "        if label not in ACCURACY_PER_LABEL:\n",
      "            ACCURACY_PER_LABEL[label] = {'total': 0, 'matches': 0}\n",
      "        if distance not in ACCURACY_PER_DISTANCE_LABELED:\n",
      "            ACCURACY_PER_DISTANCE_LABELED[distance] = {'total': 0, 'matches': 0}\n",
      "        ACCURACY_PER_LABEL[label]['total'] += 1\n",
      "        ACCURACY_PER_DISTANCE_LABELED[distance]['total'] += 1\n",
      "        if exist_same(item, origin_cons):\n",
      "            ACCURACY_PER_DISTANCE_LABELED[distance]['matches'] += 1\n",
      "            ACCURACY_PER_LABEL[label]['matches'] += 1\n",
      "            pre_count += 1\n",
      "\n",
      "    for item in origin_cons:\n",
      "        if exist_same(item, guess_cons):\n",
      "            recall_count += 1\n",
      "\n",
      "    recall = float(recall_count)/float(origin_len)\n",
      "    precision = float(pre_count)/float(guess_len)\n",
      "    f_measure = 2*(recall*precision)/(recall + precision)\n",
      "\n",
      "    return precision, recall, f_measure\n",
      "\n",
      "def calculate_accuracy_per_distance():\n",
      "    x_axis = ACCURACY_PER_DISTANCE.keys()\n",
      "    x_axis.sort()\n",
      "    y_axis = [ACCURACY_PER_DISTANCE[x]['matches']/float(ACCURACY_PER_DISTANCE[x]['total']) for x in x_axis]\n",
      "    x_axis_labeled = ACCURACY_PER_DISTANCE_LABELED.keys()\n",
      "    x_axis_labeled.sort()\n",
      "    y_axis_labeled = [ACCURACY_PER_DISTANCE_LABELED[x]['matches']/float(ACCURACY_PER_DISTANCE_LABELED[x]['total']) for x in x_axis_labeled]\n",
      "    print x_axis\n",
      "    print y_axis\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.title(\"Accuracy per distance\")\n",
      "    plt.scatter(x_axis, y_axis, c=\"blue\", marker='*', label=\"accuracy index\")\n",
      "    plt.scatter(x_axis_labeled, y_axis_labeled, c=\"red\", marker='o', label=\"accuracy label\", alpha=0.5)\n",
      "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.)\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def eval_tree(orig_tree, guess_tree):\n",
      "    origin_cons = tree_to_constituents(orig_tree)\n",
      "    guess_cons = tree_to_constituents(guess_tree)\n",
      "    origin_cons = list(origin_cons)\n",
      "    guess_cons = list(guess_cons)\n",
      "    a, b, c = calculate_joint_metrics(origin_cons, guess_cons)\n",
      "    d, e, f = calculate_index_metrics(origin_cons,guess_cons)\n",
      "    return (a,b), (d,e)\n",
      "\n",
      "\n",
      "def eval_trees(trees, parser, pcfg):\n",
      "    counter = 0\n",
      "    overall_prec_labeled = 0\n",
      "    overall_recall_labeled = 0\n",
      "    overall_prec_index = 0\n",
      "    overall_recall_index = 0\n",
      "    for tree in trees:\n",
      "        counter += 1\n",
      "        tokens = pos_uncovered_tokens(tree.leaves(), pcfg)\n",
      "        guess_tree = parser.parse(tokens)\n",
      "        guess_tree = list(guess_tree)[0]\n",
      "        # guess_tree.draw()\n",
      "        # tree.draw()\n",
      "        labaled_metrics, index_metrics = eval_tree(tree, guess_tree)\n",
      "        pre_labeled, recall_labeled = labaled_metrics\n",
      "        pre_index, recall_index = index_metrics\n",
      "        overall_prec_labeled += pre_labeled\n",
      "        overall_recall_labeled += recall_labeled\n",
      "        overall_prec_index += pre_index\n",
      "        overall_recall_index += recall_index\n",
      "\n",
      "    overall_recall_labeled = overall_recall_labeled/float(counter)\n",
      "    overall_prec_labeled = overall_prec_labeled/float(counter)\n",
      "    overall_recall_index = overall_recall_index/float(counter)\n",
      "    overall_prec_index = overall_prec_index/float(counter)\n",
      "\n",
      "    print \"precision for labeled: \", overall_prec_labeled\n",
      "    print \"recall_labeled: \", overall_recall_labeled\n",
      "    print \"fmeasure labeled \", 2*(overall_prec_labeled*overall_recall_labeled)/(overall_prec_labeled+overall_recall_labeled)\n",
      "    print\n",
      "    print \"precision for index: \", overall_prec_index\n",
      "    print \"recall_index: \", overall_recall_index\n",
      "    print \"fmeasure index \", 2*(overall_prec_index*overall_recall_index)/(overall_prec_index+overall_recall_index)\n",
      "    \n",
      "\n",
      "cleaned_trees = [filter_tree(t) for t in test_trees[:1000]]\n",
      "for t in cleaned_trees:\n",
      "    chomsky_normal_form(t, factor='right', horzMarkov=1, vertMarkov=1, childChar='|', parentChar='^')\n",
      "    \n",
      "eval_trees(cleaned_trees, parser, training_pcfg)\n",
      "\n",
      "print \"----------- Reporting Per Label -----------\"\n",
      "print ACCURACY_PER_LABEL\n",
      "for item in ACCURACY_PER_LABEL:\n",
      "    print item, \"--- total -------> \", ACCURACY_PER_LABEL[item]['total']\n",
      "    print item, \"--- precision ---> \", ACCURACY_PER_LABEL[item]['matches']/float(ACCURACY_PER_LABEL[item]['total'])\n",
      "print '-'*100\n",
      "\n",
      "print ACCURACY_PER_DISTANCE\n",
      "calculate_accuracy_per_distance()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "precision for labeled:  0.804347826087\n",
        "recall_labeled:  0.822222222222\n",
        "fmeasure labeled  0.813186813187\n",
        "\n",
        "precision for index:  0.883720930233\n",
        "recall_index:  0.883720930233\n",
        "fmeasure index  0.883720930233\n",
        "----------- Reporting Per Label -----------\n",
        "{u'QP': {'matches': 0, 'total': 1}, u'PP': {'matches': 1, 'total': 2}, u'NN': {'matches': 2, 'total': 2}, u'VBD': {'matches': 1, 'total': 1}, u'JJS': {'matches': 1, 'total': 1}, u'VBN': {'matches': 2, 'total': 2}, u'CD': {'matches': 5, 'total': 6}, u'VP': {'matches': 6, 'total': 9}, u'TO': {'matches': 2, 'total': 2}, u'S': {'matches': 3, 'total': 4}, u'VB': {'matches': 2, 'total': 2}, u'IN': {'matches': 2, 'total': 2}, u'NP': {'matches': 7, 'total': 8}, u'DT': {'matches': 1, 'total': 1}, u'.': {'matches': 1, 'total': 1}, u'NNS': {'matches': 1, 'total': 2}}\n",
        "QP --- total ------->  1\n",
        "QP --- precision --->  0.0\n",
        "PP --- total ------->  2\n",
        "PP --- precision --->  0.5\n",
        "NN --- total ------->  2\n",
        "NN --- precision --->  1.0\n",
        "VBD --- total ------->  1\n",
        "VBD --- precision --->  1.0\n",
        "JJS --- total ------->  1\n",
        "JJS --- precision --->  1.0\n",
        "VBN --- total ------->  2\n",
        "VBN --- precision --->  1.0\n",
        "CD --- total ------->  6\n",
        "CD --- precision --->  0.833333333333\n",
        "VP --- total ------->  9\n",
        "VP --- precision --->  0.666666666667\n",
        "TO --- total ------->  2\n",
        "TO --- precision --->  1.0\n",
        "S --- total ------->  4\n",
        "S --- precision --->  0.75\n",
        "VB --- total ------->  2\n",
        "VB --- precision --->  1.0\n",
        "IN --- total ------->  2\n",
        "IN --- precision --->  1.0\n",
        "NP --- total ------->  8\n",
        "NP --- precision --->  0.875\n",
        "DT --- total ------->  1\n",
        "DT --- precision --->  1.0\n",
        ". --- total ------->  1\n",
        ". --- precision --->  1.0\n",
        "NNS --- total ------->  2\n",
        "NNS --- precision --->  0.5\n",
        "----------------------------------------------------------------------------------------------------\n",
        "{1: {'matches': 22, 'total': 22}, 2: {'matches': 5, 'total': 5}, 3: {'matches': 3, 'total': 4}, 4: {'matches': 2, 'total': 3}, 6: {'matches': 0, 'total': 1}, 10: {'matches': 0, 'total': 1}, 11: {'matches': 0, 'total': 1}, 12: {'matches': 1, 'total': 1}, 15: {'matches': 1, 'total': 1}, 16: {'matches': 1, 'total': 1}, 17: {'matches': 1, 'total': 1}, 18: {'matches': 1, 'total': 1}, 22: {'matches': 1, 'total': 1}}\n",
        "[1, 2, 3, 4, 6, 10, 11, 12, 15, 16, 17, 18, 22]\n",
        "[1.0, 1.0, 0.75, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff2463140d0>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "with filtered annotations:\n",
      "    \n",
      "precision for labeled:  0.700300326027\n",
      "recall_labeled:  0.712663530466\n",
      "fmeasure labeled  0.70642784023\n",
      "precision for index:  0.929015669352\n",
      "recall_index:  0.929015669352\n",
      "fmeasure index  0.929015669352"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}