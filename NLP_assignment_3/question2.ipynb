{
 "metadata": {
  "signature": "sha256:9bffb2b1993de4b54d35c46370a0a890b10025e15f81865db1b38a80bde05066"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Question 2.1: Build a Parser"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we induce a PCFG and build a parser, we note that we must handle unknown words when we parse sentences. <br/>\n",
      "We do this by using POS tagging; before parsing a sentence, we replace each unknown word with its Part of Speech tag. As a result, the parser will have to know the Production (Penn-POS -> Universal-POS) where the Universal-POS is a terminal node replacing the original word in the sentence.<br/>\n",
      "To acheive this we define two methods:<br/>\n",
      "<ol>\n",
      "<li><b>get_parser -</b> gets a list of parsed trees, and returns (parser, pcfg) that include the POS rules mentioned above.</li>\n",
      "<li><b>pos_uncovered_tokens -</b> gets a sentence and a pcfg, and replaces each word not known in the pcfg by its part of speech (accoridng to the best tagger learned in Assignment 1)</li> \n",
      "</ol>\n",
      "As well as a mapping from Penn-POS tags to Universal-POS tags, <b>GRAMMAR_TO_POS</b>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import induce_pcfg, Nonterminal, ViterbiParser, Tree, Production, DefaultTagger\n",
      "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
      "from question1 import filter_tree, tree_to_productions, pcfg_cnf_learn\n",
      "\n",
      "from ass1 import *\n",
      "from nltk import UnigramTagger\n",
      "\n",
      "GRAMMAR_TO_POS = {\n",
      "    \"CC\": \"CONJ\",\n",
      "    \"CD\": \"NUM\",\n",
      "    \"DT\": \"DET\",\n",
      "    \"EX\": \"ADVERB\",\n",
      "    \"FW\": \"X\",\n",
      "    \"IN\": \"ADP\",\n",
      "    \"JJ\": \"ADJ\",\n",
      "    \"JJR\": \"ADJ\",\n",
      "    \"JJS\": \"ADJ\",\n",
      "    \"LS\": \".\",\n",
      "    \"MD\": \"VERB\",\n",
      "    \"NN\": \"NOUN\",\n",
      "    \"NNS\": \"NOUN\",\n",
      "    \"NNP\": \"NOUN\",\n",
      "    \"NNPS\": \"NOUN\",\n",
      "    \"PDT\": \"DET\",\n",
      "    \"POS\": \"PRON\",\n",
      "    \"PRP\": \"PRON\",\n",
      "    \"PRP$\": \"PRON\",\n",
      "    \"RB\": \"ADV\",\n",
      "    \"RBR\": \"ADV\",\n",
      "    \"RBS\": \"ADV\",\n",
      "    \"RP\": \"PRT\",\n",
      "    \"SYM\": \".\",\n",
      "    \"TO\": \"ADP\",\n",
      "    \"UH\": \"PRT\",\n",
      "    \"VB\": \"VERB\",\n",
      "    \"VBD\": \"VERB\",\n",
      "    \"VBG\": \"VERB\",\n",
      "    \"VBN\": \"VERB\",\n",
      "    \"VBP\": \"VERB\",\n",
      "    \"WDT\": \"DET\",\n",
      "    \"WP\": \"PRON\",\n",
      "    \"WP$\": \"PRON\",\n",
      "    \"WRB\": \"ADV\",\n",
      "}\n",
      "\n",
      "def get_pos_tagger():\n",
      "    all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "    train = all_words\n",
      "\n",
      "    u0 = UnigramTagger(train, backoff=DefaultTagger(\"NOUN\"))\n",
      "\n",
      "    return EntropyAffixTagger(train=train, cutoff=0.5, backoff=u0)\n",
      "\n",
      "\n",
      "tagger = get_pos_tagger()\n",
      "\n",
      "\n",
      "def pos_uncovered_tokens(test_sentence, training_pcfg):\n",
      "    pos = tagger.tag(test_sentence)\n",
      "    for i, token in enumerate(test_sentence):\n",
      "        if token not in training_pcfg._lexical_index:\n",
      "            test_sentence[i] = \"$\" + pos[i][1]\n",
      "\n",
      "    return test_sentence\n",
      "\n",
      "\n",
      "def get_parser(training_trees):\n",
      "    training_prods = sum([list(tree_to_productions(t)) for t in training_trees], list())\n",
      "    pos_rules = [Production(Nonterminal(lhs), [\"$\" + rhs]) for lhs, rhs in GRAMMAR_TO_POS.iteritems()]\n",
      "    training_prods += pos_rules\n",
      "    training_pcfg = induce_pcfg(Nonterminal(\"S\"), training_prods)\n",
      "    parser = ViterbiParser(training_pcfg)\n",
      "\n",
      "    return parser, training_pcfg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we test the annotating function on the first sentence in the test set (which already contains unknown words)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
      "trees = treebank.parsed_sents()\n",
      "eighty_perc = int(len(trees) * 0.8)\n",
      "training_trees = pcfg_cnf_learn(treebank, eighty_perc)\n",
      "test_trees = trees[eighty_perc:]\n",
      "parser, training_pcfg = get_parser(training_trees)\n",
      "\n",
      "test_tree = filter_tree(test_trees[0])\n",
      "test_sentence = test_tree.leaves()\n",
      "test_sentence = pos_uncovered_tokens(test_sentence, training_pcfg)\n",
      "\n",
      "print test_sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'The', u'latest', u'10-year', u'notes', u'were', u'quoted', u'at', u'100', u'22\\\\/32', u'to', u'yield', u'7.88', u'%', u'compared', u'with', u'100', '$NOUN', u'to', u'yield', u'7.90', u'%', u'.']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see it replaced unknown tokens by a part of speech, now let us try the parser:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(parser.parse(test_sentence))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ProbabilisticTree('S', [ProbabilisticTree('NP^<S>', [ProbabilisticTree('DT', ['The']) (p=0.08558352402745996), ProbabilisticTree('NP|<JJS>^<S>', [ProbabilisticTree('JJS', ['latest']) (p=0.0896551724137931), ProbabilisticTree('NP|<CD>^<S>', [ProbabilisticTree('CD', ['10-year']) (p=0.00039761431411530816), ProbabilisticTree('NNS', ['notes']) (p=0.005080268238162975)]) (p=6.733291236796521e-07)]) (p=6.707493186080824e-09)]) (p=8.485600949814815e-13), ProbabilisticTree('S|<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('VBD', ['were']) (p=0.06388526727509779), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VBN', ['quoted']) (p=0.0029708853238265003), ProbabilisticTree('VP|<PP>^<VP>', [ProbabilisticTree('PP^<VP>', [ProbabilisticTree('IN', ['at']) (p=0.04136099165190994), ProbabilisticTree('NP^<PP>', [ProbabilisticTree('QP^<NP>', [ProbabilisticTree('CD', ['100']) (p=0.012723658051689861), ProbabilisticTree('CD', ['22\\\\/32']) (p=0.00039761431411530816)]) (p=6.247077383094805e-07)]) (p=9.239646330539416e-09)]) (p=2.802338839278382e-10), ProbabilisticTree('S^<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('TO', ['to']) (p=0.9889277389277389), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VB', ['yield']) (p=0.010209042294603793), ProbabilisticTree('VP|<NP>^<VP>', [ProbabilisticTree('NP^<VP>', [ProbabilisticTree('NP^<NP>', [ProbabilisticTree('CD', ['7.88']) (p=0.0011928429423459245), ProbabilisticTree('NN', ['%']) (p=0.031950126631599456)]) (p=5.223329571072206e-07), ProbabilisticTree('VP^<NP>', [ProbabilisticTree('VBN', ['compared']) (p=0.0106951871657754), ProbabilisticTree('PP^<VP>', [ProbabilisticTree('IN', ['with']) (p=0.03933721224386542), ProbabilisticTree('NP^<PP>', [ProbabilisticTree('CD', ['100']) (p=0.012723658051689861), ProbabilisticTree('NNS', ['$NOUN']) (p=0.000203210729526519)]) (p=1.670753483225788e-08)]) (p=4.81937044161947e-10)]) (p=1.9845844707975737e-12)]) (p=1.7281469738403862e-20), ProbabilisticTree('S^<VP>', [ProbabilisticTree('VP^<S>', [ProbabilisticTree('TO', ['to']) (p=0.9889277389277389), ProbabilisticTree('VP^<VP>', [ProbabilisticTree('VB', ['yield']) (p=0.010209042294603793), ProbabilisticTree('NP^<VP>', [ProbabilisticTree('CD', ['7.90']) (p=0.0011928429423459245), ProbabilisticTree('NN', ['%']) (p=0.031950126631599456)]) (p=5.143386176336758e-07)]) (p=8.888250145210049e-10)]) (p=1.2109687251364533e-10)]) (p=8.788173033847405e-11)]) (p=1.033816360825318e-31)]) (p=9.784692403897867e-35)]) (p=1.3331033997266647e-35)]) (p=9.674521815159225e-36)]) (p=2.223638782604839e-46)]) (p=1.7891726191982884e-50)]) (p=4.134050800170843e-53), ProbabilisticTree('.', ['.']) (p=0.9858611825192802)]) (p=3.780448885503274e-53)]) (p=1.599421990770694e-65)]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}