{
 "metadata": {
  "signature": "sha256:40c2f471d1a3c8a2bc1c32732ec83ecf6ebf9cfeda0a125739b98a366cf383f3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Question 2.1: Build a Parser"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we induce a PCFG and build a parser, we note that we must handle unknown words when we parse sentences. <br/>\n",
      "We do this by using POS tagging; before parsing a sentence, we replace each unknown word with its Part of Speech tag. As a result, the parser will have to know the Production (Penn-POS -> Universal-POS)<sup><a>1</a></sup> where the Universal-POS is a terminal node replacing the original word in the sentence.<br/>\n",
      "To acheive this we define two methods:<br/>\n",
      "<ol>\n",
      "<li><b>get_parser -</b> gets a list of parsed trees, and returns (parser, pcfg) that include the POS rules mentioned above.</li>\n",
      "<li><b>pos_uncovered_tokens -</b> gets a sentence and a pcfg, and replaces each word not known in the pcfg by its part of speech (accoridng to the best tagger learned in Assignment 1)</li> \n",
      "</ol>\n",
      "As well as a mapping from Penn-POS tags to Universal-POS tags, <b>GRAMMAR_TO_POS</b>.<br/>\n",
      "<p>\n",
      "<sup>1. we eventually realized the brown corpus provides tagging with the Penn University tagset, but since the runtime is so long we didn't have time to re-test the parser when using proper tags.</sup></p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import induce_pcfg, Nonterminal, ViterbiParser, Tree, Production, DefaultTagger\n",
      "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
      "from question1 import filter_tree, tree_to_productions, pcfg_cnf_learn\n",
      "\n",
      "from ass1 import *\n",
      "from nltk import UnigramTagger\n",
      "\n",
      "GRAMMAR_TO_POS = {\n",
      "    \"CC\": \"CONJ\",\n",
      "    \"CD\": \"NUM\",\n",
      "    \"DT\": \"DET\",\n",
      "    \"EX\": \"ADVERB\",\n",
      "    \"FW\": \"X\",\n",
      "    \"IN\": \"ADP\",\n",
      "    \"JJ\": \"ADJ\",\n",
      "    \"JJR\": \"ADJ\",\n",
      "    \"JJS\": \"ADJ\",\n",
      "    \"LS\": \".\",\n",
      "    \"MD\": \"VERB\",\n",
      "    \"NN\": \"NOUN\",\n",
      "    \"NNS\": \"NOUN\",\n",
      "    \"NNP\": \"NOUN\",\n",
      "    \"NNPS\": \"NOUN\",\n",
      "    \"PDT\": \"DET\",\n",
      "    \"POS\": \"PRON\",\n",
      "    \"PRP\": \"PRON\",\n",
      "    \"PRP$\": \"PRON\",\n",
      "    \"RB\": \"ADV\",\n",
      "    \"RBR\": \"ADV\",\n",
      "    \"RBS\": \"ADV\",\n",
      "    \"RP\": \"PRT\",\n",
      "    \"SYM\": \".\",\n",
      "    \"TO\": \"ADP\",\n",
      "    \"UH\": \"PRT\",\n",
      "    \"VB\": \"VERB\",\n",
      "    \"VBD\": \"VERB\",\n",
      "    \"VBG\": \"VERB\",\n",
      "    \"VBN\": \"VERB\",\n",
      "    \"VBP\": \"VERB\",\n",
      "    \"WDT\": \"DET\",\n",
      "    \"WP\": \"PRON\",\n",
      "    \"WP$\": \"PRON\",\n",
      "    \"WRB\": \"ADV\",\n",
      "}\n",
      "\n",
      "def get_pos_tagger():\n",
      "    all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "    train = all_words\n",
      "\n",
      "    u0 = UnigramTagger(train, backoff=DefaultTagger(\"NOUN\"))\n",
      "\n",
      "    return EntropyAffixTagger(train=train, cutoff=0.5, backoff=u0)\n",
      "\n",
      "\n",
      "tagger = get_pos_tagger()\n",
      "\n",
      "\n",
      "def pos_uncovered_tokens(test_sentence, training_pcfg):\n",
      "    pos = tagger.tag(test_sentence)\n",
      "    for i, token in enumerate(test_sentence):\n",
      "        if token not in training_pcfg._lexical_index:\n",
      "            test_sentence[i] = \"$\" + pos[i][1]\n",
      "\n",
      "    return test_sentence\n",
      "\n",
      "\n",
      "def get_parser(training_trees):\n",
      "    training_prods = sum([list(tree_to_productions(t)) for t in training_trees], list())\n",
      "    pos_rules = [Production(Nonterminal(lhs), [\"$\" + rhs]) for lhs, rhs in GRAMMAR_TO_POS.iteritems()]\n",
      "    training_prods += pos_rules\n",
      "    training_pcfg = induce_pcfg(Nonterminal(\"S\"), training_prods)\n",
      "    parser = ViterbiParser(training_pcfg)\n",
      "\n",
      "    return parser, training_pcfg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we test the annotating function on the first sentence in the test set (which already contains unknown words)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
      "trees = treebank.parsed_sents()\n",
      "eighty_perc = int(len(trees) * 0.8)\n",
      "training_trees = pcfg_cnf_learn(treebank, eighty_perc)\n",
      "test_trees = trees[eighty_perc:]\n",
      "parser, training_pcfg = get_parser(training_trees)\n",
      "\n",
      "test_tree = filter_tree(test_trees[0])\n",
      "test_sentence = test_tree.leaves()\n",
      "test_sentence = pos_uncovered_tokens(test_sentence, training_pcfg)\n",
      "\n",
      "print test_sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'The', u'latest', u'10-year', u'notes', u'were', u'quoted', u'at', u'100', u'22\\\\/32', u'to', u'yield', u'7.88', u'%', u'compared', u'with', u'100', '$NOUN', u'to', u'yield', u'7.90', u'%', u'.']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see it replaced unknown tokens by a part of speech, now let us try the parser:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser.trace(1)\n",
      "trees = list(parser.parse(test_sentence))\n",
      "print trees[0]\n",
      "trees[0].draw()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Inserting tokens into the most likely constituents table...\n",
        "Finding the most likely constituents spanning 1 text elements...\n",
        "Finding the most likely constituents spanning 2 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 3 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 4 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 5 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 6 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 7 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 8 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 9 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 10 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 11 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 12 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 13 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 14 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 15 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 16 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 17 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 18 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 19 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 20 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 21 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finding the most likely constituents spanning 22 text elements..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(S\n",
        "  (NP^<S>\n",
        "    (DT The)\n",
        "    (NP|<JJS>^<S>\n",
        "      (JJS latest)\n",
        "      (NP|<CD>^<S> (CD 10-year) (NNS notes))))\n",
        "  (S|<VP>\n",
        "    (VP^<S>\n",
        "      (VBD were)\n",
        "      (VP^<VP>\n",
        "        (VBN quoted)\n",
        "        (VP|<PP>^<VP>\n",
        "          (PP^<VP>\n",
        "            (IN at)\n",
        "            (NP^<PP> (QP^<NP> (CD 100) (CD 22\\/32))))\n",
        "          (S^<VP>\n",
        "            (VP^<S>\n",
        "              (TO to)\n",
        "              (VP^<VP>\n",
        "                (VB yield)\n",
        "                (VP|<NP>^<VP>\n",
        "                  (NP^<VP>\n",
        "                    (NP^<NP> (CD 7.88) (NN %))\n",
        "                    (VP^<NP>\n",
        "                      (VBN compared)\n",
        "                      (PP^<VP>\n",
        "                        (IN with)\n",
        "                        (NP^<PP> (CD 100) (NNS $NOUN)))))\n",
        "                  (S^<VP>\n",
        "                    (VP^<S>\n",
        "                      (TO to)\n",
        "                      (VP^<VP>\n",
        "                        (VB yield)\n",
        "                        (NP^<VP> (CD 7.90) (NN %))))))))))))\n",
        "    (. .))) (p=1.59942e-65)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Question 2.2 - Metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from question2 import *\n",
      "parser.trace(0)\n",
      "%matplotlib inline\n",
      "ACCURACY_PER_DISTANCE = {}\n",
      "ACCURACY_PER_DISTANCE_LABELED = {}\n",
      "ACCURACY_PER_LABEL = {}\n",
      "\n",
      "\n",
      "def exist_same(con, cons_list):\n",
      "    for item in cons_list:\n",
      "        if (item[0].label().split('^')[0].split('|')[0] == con[0].label().split('^')[0].split('|')[0]) and (item[1] == con[1]) and (item[2] == con[2]):\n",
      "            return True\n",
      "#         if (item[0].label() == con[0].label()) and (item[1] == con[1]) and (item[2] == con[2]):\n",
      "#             return True\n",
      "\n",
      "    return False\n",
      "\n",
      "\n",
      "def calculate_index_metrics(origin_cons, guess_cons):\n",
      "    origin_indexes = set([(x[1], x[2]) for x in origin_cons])\n",
      "    guess_indexes = set([(x[1], x[2]) for x in guess_cons])\n",
      "    origin_len = len(origin_indexes)\n",
      "    guess_len = len(guess_indexes)\n",
      "    pre_count = 0\n",
      "    recall_count = 0\n",
      "    for item in guess_indexes:\n",
      "        distance = item[1]-item[0]+1\n",
      "        if distance not in ACCURACY_PER_DISTANCE:\n",
      "            ACCURACY_PER_DISTANCE[distance] = {'total': 0, 'matches': 0}\n",
      "\n",
      "        ACCURACY_PER_DISTANCE[distance]['total'] += 1\n",
      "\n",
      "        if item in origin_indexes:\n",
      "            ACCURACY_PER_DISTANCE[distance]['matches'] += 1\n",
      "            pre_count += 1\n",
      "\n",
      "    for item in origin_indexes:\n",
      "        if item in guess_indexes:\n",
      "            recall_count += 1\n",
      "\n",
      "    recall = float(recall_count)/float(origin_len)\n",
      "    precision = float(pre_count)/float(guess_len)\n",
      "    f_measure = 2*(recall*precision)/(recall + precision)\n",
      "\n",
      "    return precision, recall, f_measure\n",
      "\n",
      "\n",
      "def calculate_joint_metrics(origin_cons, guess_cons):\n",
      "    origin_cons = list(origin_cons)\n",
      "    guess_cons = list(guess_cons)\n",
      "    origin_len = len(list(origin_cons))\n",
      "    guess_len = len(list(guess_cons))\n",
      "\n",
      "    pre_count = 0\n",
      "    recall_count = 0\n",
      "    # calculate precision\n",
      "    for item in guess_cons:\n",
      "        distance = item[2]-item[1]+1\n",
      "        label = item[0].label().split('^')[0].split('|')[0]\n",
      "        if label not in ACCURACY_PER_LABEL:\n",
      "            ACCURACY_PER_LABEL[label] = {'total': 0, 'matches': 0}\n",
      "        if distance not in ACCURACY_PER_DISTANCE_LABELED:\n",
      "            ACCURACY_PER_DISTANCE_LABELED[distance] = {'total': 0, 'matches': 0}\n",
      "        ACCURACY_PER_LABEL[label]['total'] += 1\n",
      "        ACCURACY_PER_DISTANCE_LABELED[distance]['total'] += 1\n",
      "        if exist_same(item, origin_cons):\n",
      "            ACCURACY_PER_DISTANCE_LABELED[distance]['matches'] += 1\n",
      "            ACCURACY_PER_LABEL[label]['matches'] += 1\n",
      "            pre_count += 1\n",
      "\n",
      "    for item in origin_cons:\n",
      "        if exist_same(item, guess_cons):\n",
      "            recall_count += 1\n",
      "\n",
      "    recall = float(recall_count)/float(origin_len)\n",
      "    precision = float(pre_count)/float(guess_len)\n",
      "    f_measure = 2*(recall*precision)/(recall + precision)\n",
      "\n",
      "    return precision, recall, f_measure\n",
      "\n",
      "def calculate_accuracy_per_distance():\n",
      "    x_axis = ACCURACY_PER_DISTANCE.keys()\n",
      "    x_axis.sort()\n",
      "    y_axis = [ACCURACY_PER_DISTANCE[x]['matches']/float(ACCURACY_PER_DISTANCE[x]['total']) for x in x_axis]\n",
      "    x_axis_labeled = ACCURACY_PER_DISTANCE_LABELED.keys()\n",
      "    x_axis_labeled.sort()\n",
      "    y_axis_labeled = [ACCURACY_PER_DISTANCE_LABELED[x]['matches']/float(ACCURACY_PER_DISTANCE_LABELED[x]['total']) for x in x_axis_labeled]\n",
      "    print x_axis\n",
      "    print y_axis\n",
      "    import matplotlib.pyplot as plt\n",
      "    plt.title(\"Accuracy per distance\")\n",
      "    plt.scatter(x_axis, y_axis, c=\"blue\", marker='*', label=\"accuracy index\")\n",
      "    plt.scatter(x_axis_labeled, y_axis_labeled, c=\"red\", marker='o', label=\"accuracy label\", alpha=0.5)\n",
      "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.)\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "def eval_tree(orig_tree, guess_tree):\n",
      "    origin_cons = tree_to_constituents(orig_tree)\n",
      "    guess_cons = tree_to_constituents(guess_tree)\n",
      "    origin_cons = list(origin_cons)\n",
      "    guess_cons = list(guess_cons)\n",
      "    a, b, c = calculate_joint_metrics(origin_cons, guess_cons)\n",
      "    d, e, f = calculate_index_metrics(origin_cons,guess_cons)\n",
      "    return (a,b), (d,e)\n",
      "\n",
      "\n",
      "def eval_trees(trees, parser, pcfg):\n",
      "    counter = 0\n",
      "    overall_prec_labeled = 0\n",
      "    overall_recall_labeled = 0\n",
      "    overall_prec_index = 0\n",
      "    overall_recall_index = 0\n",
      "    for tree in trees:\n",
      "        counter += 1\n",
      "        tokens = pos_uncovered_tokens(tree.leaves(), pcfg)\n",
      "        guess_tree = parser.parse(tokens)\n",
      "        guess_tree = list(guess_tree)[0]\n",
      "        # guess_tree.draw()\n",
      "        # tree.draw()\n",
      "        labaled_metrics, index_metrics = eval_tree(tree, guess_tree)\n",
      "        pre_labeled, recall_labeled = labaled_metrics\n",
      "        pre_index, recall_index = index_metrics\n",
      "        overall_prec_labeled += pre_labeled\n",
      "        overall_recall_labeled += recall_labeled\n",
      "        overall_prec_index += pre_index\n",
      "        overall_recall_index += recall_index\n",
      "\n",
      "    overall_recall_labeled = overall_recall_labeled/float(counter)\n",
      "    overall_prec_labeled = overall_prec_labeled/float(counter)\n",
      "    overall_recall_index = overall_recall_index/float(counter)\n",
      "    overall_prec_index = overall_prec_index/float(counter)\n",
      "\n",
      "    print \"precision for labeled: \", overall_prec_labeled\n",
      "    print \"recall_labeled: \", overall_recall_labeled\n",
      "    print \"fmeasure labeled \", 2*(overall_prec_labeled*overall_recall_labeled)/(overall_prec_labeled+overall_recall_labeled)\n",
      "    print\n",
      "    print \"precision for index: \", overall_prec_index\n",
      "    print \"recall_index: \", overall_recall_index\n",
      "    print \"fmeasure index \", 2*(overall_prec_index*overall_recall_index)/(overall_prec_index+overall_recall_index)\n",
      "    \n",
      "\n",
      "cleaned_trees = [filter_tree(t) for t in test_trees[:1000]]\n",
      "for t in cleaned_trees:\n",
      "    chomsky_normal_form(t, factor='right', horzMarkov=1, vertMarkov=1, childChar='|', parentChar='^')\n",
      "    \n",
      "eval_trees(cleaned_trees, parser, training_pcfg)\n",
      "\n",
      "print \"----------- Reporting Per Label -----------\"\n",
      "print ACCURACY_PER_LABEL\n",
      "for item in ACCURACY_PER_LABEL:\n",
      "    print item, \"--- total -------> \", ACCURACY_PER_LABEL[item]['total']\n",
      "    print item, \"--- precision ---> \", ACCURACY_PER_LABEL[item]['matches']/float(ACCURACY_PER_LABEL[item]['total'])\n",
      "print '-'*100\n",
      "\n",
      "print ACCURACY_PER_DISTANCE\n",
      "calculate_accuracy_per_distance()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "precision for labeled:  0.804347826087\n",
        "recall_labeled:  0.822222222222\n",
        "fmeasure labeled  0.813186813187\n",
        "\n",
        "precision for index:  0.883720930233\n",
        "recall_index:  0.883720930233\n",
        "fmeasure index  0.883720930233\n",
        "----------- Reporting Per Label -----------\n",
        "{u'QP': {'matches': 0, 'total': 1}, u'PP': {'matches': 1, 'total': 2}, u'NN': {'matches': 2, 'total': 2}, u'VBD': {'matches': 1, 'total': 1}, u'JJS': {'matches': 1, 'total': 1}, u'VBN': {'matches': 2, 'total': 2}, u'CD': {'matches': 5, 'total': 6}, u'VP': {'matches': 6, 'total': 9}, u'TO': {'matches': 2, 'total': 2}, u'S': {'matches': 3, 'total': 4}, u'VB': {'matches': 2, 'total': 2}, u'IN': {'matches': 2, 'total': 2}, u'NP': {'matches': 7, 'total': 8}, u'DT': {'matches': 1, 'total': 1}, u'.': {'matches': 1, 'total': 1}, u'NNS': {'matches': 1, 'total': 2}}\n",
        "QP --- total ------->  1\n",
        "QP --- precision --->  0.0\n",
        "PP --- total ------->  2\n",
        "PP --- precision --->  0.5\n",
        "NN --- total ------->  2\n",
        "NN --- precision --->  1.0\n",
        "VBD --- total ------->  1\n",
        "VBD --- precision --->  1.0\n",
        "JJS --- total ------->  1\n",
        "JJS --- precision --->  1.0\n",
        "VBN --- total ------->  2\n",
        "VBN --- precision --->  1.0\n",
        "CD --- total ------->  6\n",
        "CD --- precision --->  0.833333333333\n",
        "VP --- total ------->  9\n",
        "VP --- precision --->  0.666666666667\n",
        "TO --- total ------->  2\n",
        "TO --- precision --->  1.0\n",
        "S --- total ------->  4\n",
        "S --- precision --->  0.75\n",
        "VB --- total ------->  2\n",
        "VB --- precision --->  1.0\n",
        "IN --- total ------->  2\n",
        "IN --- precision --->  1.0\n",
        "NP --- total ------->  8\n",
        "NP --- precision --->  0.875\n",
        "DT --- total ------->  1\n",
        "DT --- precision --->  1.0\n",
        ". --- total ------->  1\n",
        ". --- precision --->  1.0\n",
        "NNS --- total ------->  2\n",
        "NNS --- precision --->  0.5\n",
        "----------------------------------------------------------------------------------------------------\n",
        "{1: {'matches': 22, 'total': 22}, 2: {'matches': 5, 'total': 5}, 3: {'matches': 3, 'total': 4}, 4: {'matches': 2, 'total': 3}, 6: {'matches': 0, 'total': 1}, 10: {'matches': 0, 'total': 1}, 11: {'matches': 0, 'total': 1}, 12: {'matches': 1, 'total': 1}, 15: {'matches': 1, 'total': 1}, 16: {'matches': 1, 'total': 1}, 17: {'matches': 1, 'total': 1}, 18: {'matches': 1, 'total': 1}, 22: {'matches': 1, 'total': 1}}\n",
        "[1, 2, 3, 4, 6, 10, 11, 12, 15, 16, 17, 18, 22]\n",
        "[1.0, 1.0, 0.75, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl0VPX9xvH3ZAOBQFZpgJAgARQBQ1lEERlREbEFxFbE\nQkFUbKtWiy2KqIk9tVKtti4UERHB81NcKhZkFTAiICCyhVXCEpIge0jJYrb5/v6YcZplEkgmZJK5\nz+scDnNzPzP3c3PnPpl87xIQEREREREREREREREREREREREREZGLzObrBgCCgoL+W1JSEurrPkRE\nGpOgoKBzJSUlLWvynAYR+oAxxvi6BxGRRsVms0ENczzg4rQiIiINkUJfRMRCFPoiIhai0Be3oUOH\n8u6779bqucnJyYwdO7aOOxJp2Ox2O7Nnz76g2vj4eFatWlWr5Xjz3IqC6uRVxC8sWbKk1s91HVAS\nsRSbzXbB7/2a1Nblcyvyi0/6x48fZ/78+b5u46IwxqAzm6QuGWPYtm0bSz/9lK/Xr6ekpMTXLdUp\n7TPVaxShv2rVKjIyMjzOO3fuHP/61xvcc89ETp06RVFRkcc6b94E06ZNIyEhgZYtW3LllVfy6aef\nlps/a9Ysunbt6p6/detWADIyMhg5ciSXXnopUVFRPPzww0DloZDDhw8TEBCAw+EAnL8yPvXUU/Tv\n35/mzZtz8OBB5syZ415Gx44defPNN8v18J///IfExERatWpFQkICy5cv56OPPqJ3797l6l5++WVG\njBjhcT3L/qr6zjvvcN111/GnP/2JiIgILrvsMpYtW+auPXToEAMHDqRly5YMHjyYU6dOlXutDRs2\ncO211xIeHk5iYiJffvklAOvXryc6OprMzEwAtm/fTkREBN99990FbAm5EPn5+axbt47VK1e6v89l\nLV2wgG9eeomwRYs4NGMG782c6X7vleVNeFplnynrwIEDDBo0iKioKKKjoxkzZgw5OTnlajZt2sSV\nV15JREQEEyZMoLCw0D3vs88+IzExkfDwcPr3709qaup5l9mYGU8cDocpLS01MTEJ5sEH/2AcDke5\n+d98840BTGDgJaZJk94GMLfccpvH10lM7G127tzpcTnn89FHH5nvv//eGGPMBx98YJo3b26OHTtm\njDHmww8/NG3btjWbN282xhiTlpZm0tPTTUlJienRo4eZNGmSyc/PNz/88INZt26dMcaY5ORkM2bM\nGPfrHzp0yNhsNlNaWmqMMWbgwIEmLi7O7N6925SWlpri4mKzePFic/DgQWOMMV9++aVp1qyZ2bJl\nizHGmI0bN5pWrVqZlStXGmOMycrKMnv37jWFhYUmIiLC7Nmzx72sxMRE88knn3hcT7vdbmbPnm2M\nMWbOnDkmODjYvPXWW8bhcJgZM2aYNm3auGv79etnHnvsMVNUVGTWrFljQkNDzdixY40xxmRmZprI\nyEizdOlSY4wxn3/+uYmMjDSnTp0yxhgzdepUM2jQIJOfn2+6detmpk+fXqvtIpXl5eWZV55+2nwy\nZoxZPX68eXHCBLN79+5y8/96zz2mYOpUY5KSTOkzz5jp48aZ9PR0d01paalZsmCB+cvEieYvEyea\n5YsWVdr3zseK+0xaWppZuXKlKSoqMidPnjTXX3+9efTRR921cXFxpnv37iYzM9OcOXPG9O/f3zz1\n1FPGGGO2bNliLr30UrNp0ybjcDjM3LlzTXx8vCkqKjLGGBMfH29WrVpVaflAo/2VxuM39N57JxrA\nNGnS0QQFNTeAWbRoUbma11573TRpEmPgPhMXd7k5efJkuflz5swxkyZNMoAZMmSomTZtmsnJyfG4\nvAuVmJhoFi5caIwxZvDgwebVV1+tVLN+/XoTHR3tflOWlZSUVO0b2G63m6SkpGp7GDFihHnllVeM\nMcZMnDjRTJo0yWPdb37zGzN16lRjjDE7d+404eHh7jdSRRVDPyEhwT0vLy/P2Gw2c/z4cZOenm6C\ngoJMfn6+e/7dd9/tDv1p06a5H//olltuMXPnzjXGGFNcXGx69eplunXrZm699dZq11NqZu3atWbB\n2LHGJCUZk5RkDvz+92b6M8+45+fk5JgXxo83jmeecdfMuecek5aW5q756osvzNtjxpi8J580uVOm\nmFm/+pX5eu1ar/qywj5T0YIFC0zPnj3d0/Hx8WbmzJnu6SVLlpiOHTu6l/n000+Xe36XLl3MmjVr\n3M+tq9Bv0MM7L7zwPN2796GwsD9BQZfx6KOPMXTo0HI1JSUllJScpmPHjZw5c4KIiIhy89eu/ZaX\nX34Z+AfLl69l9uz3Pf4qW5158+bRs2dPwsPDCQ8PZ+fOne7hjMzMTDp27FjpORkZGcTFxREQULtv\ncWxsbLnppUuX0q9fPyIjIwkPD2fJkiWcPn262h4Axo0bx3vvvQfAu+++y6hRowgODr6gHn7yk5+4\nHzdr1gyA3Nxcjh49Snh4OJdccol7flxcnHsoID09nY8++sj9/QoPD2fdunUcO3YMgKCgIMaNG8eu\nXbt47LHHLqgXuTCFBQW0KvOeC2valKL8fPd0aGgoEd26sSw9nRN5eWzIyiI7Opq2bdu6aw7v2EH/\nsDCaBQfTPCSEa1u14vDOnTXqw4r7zPHjx7nrrrto164drVq1YuzYse7leeqxffv2HD16FHDuMy+9\n9FK5fSYzM9M9vy416NCPiIggL6+A6OgvKSnZT3BwSKU3xNCht7Jjx1b27PmW99+fV2n+rFmvEhkZ\nS0jISxjzXz76aC5hYWEX3EN6ejoTJ05k+vTpnDlzhuzsbLp16+YOuNjYWNLS0io9LzY2liNHjlBa\nWlppXosWLcgvsyP+GIZllT1SX1hYyB133MHkyZM5ceIE2dnZDB069Lw9APTr14+QkBDWrFnD+++/\nXyenVcbExJCdnV1uHdLT0909t2/fnrFjx5Kdne3+d+7cOSZPngxAVlYWf/7zn5kwYQKTJk2q8jiM\n1FynLl34NjCQQ9nZnCkoYOnRo3S+5hr3fJvNxujf/pb8QYP4MCSEtJ49+fXkyTRt2tRd0zwigmNl\n358FBTSv8GGqOlbdZ5588kkCAwPZuXMnOTk5vPvuu5U+YB45cqTc4x9/2LZv356pU6eW22dyc3MZ\nNWrUBS27Jhp06AO8+OKzHDiQyvbt3/KLX1Q+mNK5c2e6du1KcHAwt912W6X5OTk5NG0awIwZz9Kr\nV3/27dtXo+Xn5eVhs9mIiorC4XAwZ84cdpb51HPffffx97//nS1btmCMIS0tjSNHjnD11VcTExPD\nE088QX5+Pj/88APr168HIDExkTVr1pCRkUFOTg7PP/98peWaMgfQioqKKCoqIioqioCAAJYuXcqK\nFSvc8++9917mzJnD6tWrcTgcZGVllVvPsWPH8tBDDxESEsK1115bo/X3JC4ujt69e5OUlERxcTFr\n167ls88+c88fM2YMixYtYsWKFZSWlvLDDz+QkpJCVlYWxhjGjx/Pfffdx1tvvUVMTAxPP/201z2J\nU2xsLLf98Y8sDQtjbmkp4bffzuBhw8rVNGvWjDt+/Wseeu45xvzud0RGRpabb7/tNr6JiODjw4f5\nKD2d7ZdeyvWDB19wD1bdZ3Jzc2nevDktW7YkKyuLF198sVJ/06dPJysrizNnzvDcc8+5Q/3+++/n\njTfeYNOmTRhjyMvLY/HixeTm5l7Qshsjj2NiDcXUqVNNRESEiYqKMpMmTao0jvfGG2+YLl26mBYt\nWpju3bubbdu2GWOMOXLkiBkxYoSJjIw0UVFR5pFHHnE/58EHHzRhYWGmU6dOZtasWSYgIKDc+GTF\nccLp06eb1q1bm7CwMDN27FgzevTocmOACxYsMD169DChoaGmU6dOZsWKFe556enpJiAgwCQnJ1e7\nnmWX+84775gBAwaUmx8QEGAOHDhgjDHm4MGDZsCAAaZFixbm5ptvNg8//HC5cfyNGzeagQMHmoiI\nCBMdHW1+9rOfmSNHjph//vOfJjEx0RQXFxtjjDl69KiJjo42a70cM5a6de7cOfPtt9+aLVu2mLy8\nvBo/34r7zK5du0yvXr1MixYtTM+ePc1LL71kYmNj3bXx8fFm2rRppmvXriYsLMyMHz/eFBQUuOcv\nW7bM9OnTx4SFhZmYmBhz5513mtzcXPdz62pMv6FcUePqXy6GgoICWrduzdatW6scxxSR/2ks+4zu\nsikezZgxg759+zboN69IQ+LP+4xuw+Dn4uPjsdlslS6OERHP/H2f0fCOiEgjpeEdERGplkJfRMRC\nFPoiIhZSFwdy3wZuA04A3T3M/xUwGee40zngt8COck0EBZ2z2WyhddCLiIhlBAUFnfPFrbEHAD2B\nqu4Deg3QyvV4CLChPpoSASKAQ8B156mzA57v3S0iHsVTdeiXFQ5UvsG3SN27H8gF/nUBtXbgyPmK\nROR/4rmw0P8j8OZ5q0REpEGL5/yhfwOwG+enfRER8YH6uiK3BzAL55h+dsWZHTt2NAcOHKinVkRE\n/MYBIKEmT6iPUzbbA58AYwCPN7A+cOCA++9x+uO/pKQkn/eg9dP6WXH9/HndjDEANb45UF180n8f\nGAhE4TwDIgn48c/MzASewTmkM8P1tWKgbx0sV0REaqguQn/0eebf5/onIiI+pity64Hdbvd1CxeV\n1q9x8+f18+d1qy3dZVNEpJHSXTZFRKRaCn0REQtR6IuIWIhCX0TEQhT6IiIWotAXEbEQhb6IiIUo\n9EVELEShLyJiIQp9ERELUeiLiFiIQl9ExEIU+iIiFqLQFxGxEIW+iIiFKPRFRCxEoS8iYiEKfRER\nC1Hoi4hYiEJfRMRCFPoiIhbibei/DRwHUqupeRXYD2wHenq5PBER8YK3oT8HGFLN/KFAAtAJmAjM\n8HJ5fu/48eMXpVYaltLSUk6dOuXTHgoKCti6dStnz549b21xcTGpqakcP34cY0y1taWlpezfv5+D\nBw/icDiqrTXGkJWVxc6dOykpKalR/75SVFTEtm3bOHnypK9bqRVvQ/8rILua+cOAua7HG4EwoLWX\ny/Rb3377LXFx8Zw7d+68tdnZ2cTGtic1tbpfsqSheu2117nppmE+W356ejqv/OlPPNy3H8mjR/PV\n6tVV1p4+fZp/JSfz2PU3MHX4CP4zf36VwV9QUMDbL7/M4zcNYcqQ25j3+usUFRV5rC0tLeXDOXOY\n+vNhPD5oMG/85S/k5OTUyfpdLCdOnGD600/z2AA7T91+O599/PF5fwj6o3iqHt5ZBFxbZnol0MtD\nnbGy7Oxsc8stt5vLLrvSgM10736NufvuCcbhcFSqdTgcZtSocaZbt6sN2ExCQndz660jTU5Ojg86\nl5ratGmTGTBgqAkLizE2W4C59tpbzbRpL9VrDw6Hw9zcvad5NjLGJIF5PjTcDI6JNVu2bPFYP3ro\nz80T0e1MEpjnmjQ3v7i0jZk/f77H2sm/f9T8LrqtedYWZJ4NCDH3Rrcxf0lK8lj7xhtvmLuj25i/\nBF9ikgkwj13aztx31911tZoXxR033Gym/vi9aBpqRlzaxixcuNBn/QA1/okTVNMn1IKtwrTHJpOT\nk92P7XY7drv94nXUwISGhhIX144VKxYDC9m1ayQTJozGZqv4rQObzUavXlfx4Yf/B3zGgQPDufnm\nG2nRokW99y01Fx8fT2FhAfn5bTHmIXbufIXnnptcrz0UFhbStmUz2HkC+AVFuYtIiIqscigmqmkw\nwdmngJsoLU4l3mEICfIcHeEhQQTm5wLdsVFI1A/HaFlFbfOgINqWlOAojcYQR9OcbwkMqY9Iqr2o\nS4IJPHMSGEJp0TdcFmAjqIr1uxhSUlJISUnx6jUudrdZQGyZ6Xaur1VSNvStJjAwkIcfnsibb74G\n/JygoOZMnHhvlfW/+c19PPnkFEpKbsMYeOSR3xAQoBOxGoPo6Gh+/etfsGnTg8BmOnYcWO8fcJo0\naULXa67h+42baVnyMQUGml/eiTZt2nis7223s3X1WlqdXUmRA0joR0Lnzh5re1xzDSs/XkDw4a1g\noKTNFVzZp4/H2i7du7M9vi3FW7di4wh5rdpyzcCBdbWaF0WfG24g9asNhJ1bRqEDbAnX0aFDh3pb\nfsUPxM8++2yNX+NiJ8VC4Neux/2AszjP9pEK8vLy+O1vf8++ffu4446R5ObmVll77tw5Ro26i+++\n+44HHnio2lppeEJCmvLii/9g/fr1XHVVp3pfvs1m4+f33suWDvE0GTmSPV27E3vzzcTExHis//mY\nMWyPjYGf/YzDP+1Nac9edOvWzWPtoKFDORgfT+6NN3Lm+oFkduzIgEGDPNb26t2bnCt7kHV1P0qG\nDGF3bFtu/eUv62o1L4ph48axrV0MtmHDOJD4U0L69qNLly6+bqtGKo8f1Mz7wEAgCmeYJwHBrnkz\nXf+/jvMMnzzgHmCLh9dxDU+JSH0pKiri9OnThIaGnnd4sKSkhNOnT9OkSRPCwsKqrXU4HJw+fRqb\nzUZkZKTHYcofGWPIzs6muLiYqKgoAgMDa7Uu9amkpIRTp05xySWX0KpVK5/24vre1ijHvQ39uqLQ\nFxGpodqEvgaCRUQsRKEvImIhCn0REQtR6IuIWIhCX0TEQhT6IiIWotAXEbGQhn2jCwvJy8tj9eLF\nZGdl0aZLFwbefDPBwcHnf6KISA3o4qwGoLi4mDeff56EQ4foGBrKlrNnKb3+eu66995qr2YUEWvT\nxVmNVEZGBk0PHeKWuDgSIiK4Iz6e9LVryc/P93VrIuJnFPoNhAPcf4zBAOgTvohcBBrTbwDat29P\naadOLN63j8tatGDrf/9Lx5tuonnz5r5uTUT8TEP5OGnpMX1w/pm5L1es4OyxY8QkJHCd3d4o7jgo\nIr6ju2yKiFiIDuSKiEi1FPoiIhai0BcRsRCFvoiIhSj0RUQsROfpN0KlpaVsWLuW7w8eJDwmhgGD\nBhESEuLrtkSkEdApm43Qx/PmUfD551zVogVpeXlkX3UV4x99VOf1i1iMTtm0gNzcXA588QWjO3Sg\nR+vW3N6hA0WpqWRlZfm6NRFpBBT6jYzD4SAACHDdm8dmsxEcEIDD4fBtYyLSKNRF6A8B9gL7gcc9\nzI8ClgHbgJ3A+DpYpmWFhobSulcvFh4+zOGzZ1mZns4PcXG0bdvW162JSCPg7Zh+ILAPuAnIAr4B\nRgN7ytQkA02AKTh/AOwDWgMlZWo0pl8DhYWFrFq8mGP79xPerh03DRtGaGior9sSkXpWmzF9b8/e\n6QukAYdd0/OB4ZQP/e+BHq7HLYHTlA98qaEmTZowdORIX7chIo2Qt6HfFsgoM50JXF2hZhawGjgK\nhAJ3erlMERGpJW9D/0LGZJ7EOZ5vBzoCnwNXAefKFiUnJ7sf2+127Ha7l62JiPiXlJQUUlJSvHoN\nb8f0++Ecsx/imp6C849A/a1MzRLgOWCda3oVzgO+m8vUaExfRKSGfHGe/magExAPhACjgIUVavbi\nPNALzgO4XYCDXi5XRERqwdvhnRLgIWA5zjN5ZuM8iPuAa/5M4K/AHGA7zh8yk4EzXi5XRERqQbdh\nEBFppHQbBvEoOzubDz/8kN27d3O+H665ubmkpqayZ88eiouL66lDEakv+qTv59LS0vj4hRfYMHce\nHXv3os8993DnhAkEBFT+eX/ixAnmTZtGbHY2BcZQePnljP/DH2jSpIkPOheR8/HFxVnSwD0wfCR9\nDx7mp8Vg27iZd7alckl0NMOHD69U+/nHHzMwN5c+cXEYY1iwezcb1q1j4KBBPuhcRC4GDe/4ua4d\n42nhKMVhrsfGJfRpH0tkZKTH2nMnTtDWdTsHm81GuyZNOHdGx9xF/IlC38/1vOEGDmEIsK3mv6U5\nnI6OJD4+3mNtbPfufH3yJKUOB3lFRWz54QdiExLqt2ERuag0pu/nzp49y313/JLLoyPJPHmK6+4a\nxX333++xtqioiE/mzSNt3ToIDOSaO+5g0JAhP44bikgDU5sx/YayNyv0L7KioiKCgoI8HsCtqLi4\nmICAAP0lLpEGTqEvImIhOk9fRESqpdAXEbEQhb6IiIUo9EVELEShLyJiIQp9qaS4uPi8N2YTkcZJ\noS+V3HnneF5/fbqv2xCRi0A3XBO3Tz75lM8/T2Hx4gVs2LCB3bvTeOCB8SQmJvq6NRGpI/qkL24B\nAQG8/fZsiosncvJkWz755D+6rbKIn1Hoi9uIEcMYPPg2AgJmUlq6nilTHuWKK67wdVsiUoc0vCPl\nFBcX8K9/vcquXd9x7NgpX7cjInVM994REWmkdO8dERGplkJfRMRCFPoiIhZSF6E/BNgL7Acer6LG\nDmwFdgIpdbBMERGpBW8P5AYC+4CbgCzgG2A0sKdMTRiwDrgFyASigIqnhehArohIDfniQG5fIA04\nDBQD84HhFWruBv6NM/ChcuCLiEg98Tb02wIZZaYzXV8rqxMQAXwBbAbGerlMERGpJW8vzrqQMZlg\n4KfAjUAz4GtgA85jAG7Jycnux3a7Hbvd7mVrIiL+JSUlhZSUFK9ew9sx/X5AMs6DuQBTAAfwtzI1\njwOXuOoA3gKWAR+XqdGYvohIDfliTH8zzuGbeCAEGAUsrFDzH+A6nAd9mwFXA7u9XK6IiNSCt8M7\nJcBDwHKcoT4b55k7D7jmz8R5OucyYAfO3wJmodAXEfEJ3XtHRKSR0r13RESkWgp9ERELUeiLiFiI\nQl9ExEIU+iIiFqLQFxGxEIW+iIiFKPRFRCzE2ytyRaSGCgoK2LZtG0WFhXTq3Jk2bdr4uiWxEF2R\nK1KP8vPzeWvaNNodPkyrgAC2BAUxfPJkOnfu7OvWpBHSFbkiDdy3mzfT/tAhRl52GTfGx3N7s2as\nnj/f122JhSj0RepRYUEB4UH/G1UNa9qUwrw8H3YkVqPQF6lHnS6/nM02G+lnz5JdUMDy77+nc79+\nvm5LLERj+iL1bGdqKikffEBRQQGX9+/P4GHDCArSORVSc7UZ01foi4g0UjqQKyIi1VLoi4hYiEJf\nRMRCFPoiIhai0BcRsRCFvoiIhSj0RUQsRKEvImIhdRH6Q4C9wH7g8Wrq+gAlwMg6WKaIiNSCt6Ef\nCLyOM/i7AqOBK6qo+xuwjIZzFbCIiOV4G/p9gTTgMFAMzAeGe6h7GPgYOOnl8kRExAvehn5bIKPM\ndKbraxVrhgMzXNO6yY6IiI94e2u/CwnwfwJPuGptVDG8k5yc7H5st9ux2+1etiYi4l9SUlJISUnx\n6jW8HV/vByTjHNMHmAI4cI7f/+hgmeVEAfnA/cDCMjW6y6aISA354tbKQcA+4EbgKLAJ58HcPVXU\nzwEWAZ9U+LpCX0SkhmoT+t4O75QADwHLcZ6hMxtn4D/gmj/Ty9cXEZE61FBOn9QnfRGRGtIfURER\nkWop9EVELEShLyJiIQp9ERELUeiLiFiIQl9ExEIU+iIiFqLQFxGxEIW+iIiFKPRFRCxEoS8iYiEK\nfRERC1Hoi4hYiEJfRMRCFPoiIhai0BcRsRCFvoiIhSj0RUQsRKEvImIhCn0REQtR6IuIWIhCX0TE\nQhT6IiIWUhehPwTYC+wHHvcw/1fAdmAHsA7oUQfLFBGRWrB5+fxAYB9wE5AFfAOMBvaUqbkG2A3k\n4PwBkQz0q/A6xhjjZSsiItZis9mghjnu7Sf9vkAacBgoBuYDwyvUfI0z8AE2Au28XKaIiNSSt6Hf\nFsgoM53p+lpV7gWWeLlMERGppSAvn1+TMZkbgAlAf08zk5OT3Y/tdjt2u92bvkRE/E5KSgopKSle\nvYa3Y/r9cI7RD3FNTwEcwN8q1PUAPnHVpXl4HY3pi4jUkC/G9DcDnYB4IAQYBSysUNMeZ+CPwXPg\ni4hIPfF2eKcEeAhYjvNMntk4z9x5wDV/JvAMEA7McH2tGOcBYBERqWfeDu/UFQ3viIjUkC+Gd0RE\npBFR6IuIWIhCX0TEQhT6IiIWotAXEbEQhb6IiIUo9EVELEShLyJiIQp9ERELUeiLiFiIQl9ExEIU\n+iIiFqLQFxGxEIW+iIiFKPRFRCxEoS8iYiEKfRERC1Hoi4hYiEJfRMRCFPoiIhai0BcRsRCFvoiI\nhSj0RUQspC5CfwiwF9gPPF5Fzauu+duBnnWwTBERqQVvQz8QeB1n8HcFRgNXVKgZCiQAnYCJwAwv\nlymNUEZGBn+dPJlf2gfx5cqVOBwOX7dULWMM69es4Vc3DyH5kUc4dOhQtfWpO3bw+7t/xe/uHM2O\n7dvrqUuRmgvy8vl9gTTgsGt6PjAc2FOmZhgw1/V4IxAGtAaOe7lsaSSOHDnCC7/7He127qb9kSOs\n+SscOniQ8RMn+rq1Kn343nvsfvttYr5cR9Cu3fzju+94+NVX6dSpU6XatV99xad//jMtN23FOAzv\nnjnJbVOnYr/hBh90LlI9bz/ptwUyykxnur52vpp2Xi5XGpGlS5eSvWQpRUdOEWa7nNwvvuD9V173\ndVvVev/V18hdvZpWJh5z/Bznli3n03//22PtB7PeIm/lSprkNqVpfnPyVq3ig1mz6rljkQvj7Sd9\nc4F1tvM9Lzk52f3Ybrdjt9tr3ZQ0LN27d6eg/7X8d903GJNNZHQbhgy9xddtVeuWobeSl3WM/KM5\nQBE9+/ahW69eHmsHDrqBo1u3cHZXJmCjS9criRk0qF77FWtISUkhJSXFq9eoGMY11Q9IxjmmDzAF\ncAB/K1PzBpCCc+gHnAd9B1J+eMcYc6E/P6Sxyc3NZezgW4jclkrCT1rzaWYGr331JX2uvtrXrVUp\ndccOJl7Tn6GR0Rw9c4b0hMt4L2U1YWFhlWozMzO5++r+9CssJMBmY11QIP+3cT3t27f3QediJTab\nDWqY496GfhCwD7gROApswnkwt+yY/lDgIdf//YB/uv4vS6Hv5zIyMtiyaRO2khLC27RhwIABvm7p\nvL7++mtOHjkCQUF0/+lP6dChQ5W1qampHNq7F2MMHS6/nB49etRjp2JVvgh9gFtxBnkgMBt4HnjA\nNW+m6/8fz/DJA+4BtlR4DYW+iEgN+Sr064JCX0SkhmoT+roiV0TEQhT6IiIWotAXEbEQhb6IiIUo\n9EVELETDNdsNAAADoklEQVShLyJiIQp9ERELUeiLiFiIQl9ExEIU+iIiFqLQFxGxEIW+iIiFKPRF\nRCxEoS8iYiEKfRERC1Hoi4hYiEJfRMRCFPoiIhai0BcRsRCFvoiIhSj0RUQsRKEvImIh3oR+BPA5\n8B2wAgjzUBMLfAHsAnYCv/dieSIi4iVvQv8JnKHfGVjlmq6oGPgDcCXQD3gQuMKLZTZKKSkpvm7h\notL6NW7+vH7+vG615U3oDwPmuh7PBUZ4qDkGbHM9zgX2AG28WGaj5O9vPK1f4+bP6+fP61Zb3oR+\na+C46/Fx13R14oGewEYvlikiIl4IOs/8z4GfePj61ArTxvWvKi2Aj4FHcH7iFxERH7B58dy9gB3n\nEE4MzgO2l3uoCwY+A5YC/6zitdKAjl70IiJiRQeAhPpa2AvA467HTwDTPNTYgHnAP+qrKRERuTgi\ngJVUPmWzDbDY9fg6wIHzYO5W178h9dumiIiIiIj4VDKQif/9RjAE5/GP/fxvOMyfHAZ24Nxmm3zb\nitfexnkmWmqZr13IRYiNhaf1S8Z/9ruqLgb1l21Y1fol00i3YRIwyddN1LFAnAep43Ee0N6G/12c\ndgjnTuUPBuA8rbhsKL4ATHY9fhzPx64aC0/r50/73U+ARNfjFsA+nPubv2zDqtavRtuwod17x5uz\niRqivjhD/zDOq5PnA8N92dBF4i/b7Ssgu8LXLuQixMbC0/qB/2w/TxeDtsV/tmFV6wc12IYNLfQf\nBrYDs2m8v4KV1RbIKDOdyf82kr8wOA/obwbu93EvF0NNL0JsjPxtv4PyF4P64zaMx7l+G1zTF7wN\n6zv0P8f5q2XFf8OAGUAHnL++fA+8VM+9XQzVXbDmL/rjfPPdivPeSgN8285Fdb6LEBsjf9zvWgD/\nxnkx6LkK8/xhG1a82NUvtmE85ccdG6t+wLIy01Pwz4O5P0oCHvN1E16Kp/x7by//uyo9xjXdmMVT\n9b5V3bzGIhhYDjxa5mv+tA09rV9Z8ZxnGzak4Z2YMo9vp/G/+cA55NEJ54YIAUYBC33ZUB1rBoS6\nHjcHBuMf262shcA41+NxwKc+7OVi8Kf9zoZzeGM35a/+95dtWNX6NdptOA/nqX/bcW4Ufxh3A+ew\nxz6cB3Sn+LiXutYB54GlbThPIWvs6/c+cBQownks5h6qvgixMaq4fhPwr/2uqotB/WUbelq/W/Gv\nbSgiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIi0jD9PwI2d5XshQD8AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff2463140d0>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "with filtered annotations:\n",
      "    \n",
      "precision for labeled:  0.700300326027\n",
      "recall_labeled:  0.712663530466\n",
      "fmeasure labeled  0.70642784023\n",
      "precision for index:  0.929015669352\n",
      "recall_index:  0.929015669352\n",
      "fmeasure index  0.929015669352"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>We attach the results for 50 sentences, since that's the longest run we managed.</b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<pre>\n",
      "precision for labeled:  0.694685977399\n",
      "recall_labeled:  0.698682048624\n",
      "fmeasure labeled  0.696678282801\n",
      "\n",
      "precision for index:  0.820438124661\n",
      "recall_index:  0.820438124661\n",
      "fmeasure index  0.820438124661\n",
      "----------- Reporting Per Label -----------\n",
      "{u'PRP$': {'matches': 4, 'total': 4}, u'VBG': {'matches': 4, 'total': 8}, u'SBAR': {'matches': 16, 'total': 24}, u'VBD': {'matches': 45, 'total': 48}, u'ADJP': {'matches': 16, 'total': 31}, u'``': {'matches': 3, 'total': 3}, u'VBN': {'matches': 18, 'total': 23}, u'POS': {'matches': 19, 'total': 19}, u\"''\": {'matches': 3, 'total': 3}, 'VBP': {'matches': 4, 'total': 5}, u'WDT': {'matches': 2, 'total': 5}, 'JJ': {'matches': 52, 'total': 60}, u'VBZ': {'matches': 5, 'total': 6}, u'DT': {'matches': 68, 'total': 68}, u'PP': {'matches': 72, 'total': 109}, u'RP': {'matches': 0, 'total': 1}, u'$': {'matches': 14, 'total': 14}, u'NN': {'matches': 163, 'total': 178}, u',': {'matches': 35, 'total': 35}, u'.': {'matches': 39, 'total': 39}, u'TO': {'matches': 25, 'total': 25}, u'PRP': {'matches': 8, 'total': 8}, u'RB': {'matches': 25, 'total': 28}, u'NP': {'matches': 355, 'total': 457}, u':': {'matches': 2, 'total': 2}, u'NNS': {'matches': 48, 'total': 62}, u'NNP': {'matches': 62, 'total': 72}, u'VB': {'matches': 15, 'total': 16}, u'MD': {'matches': 5, 'total': 6}, u'CC': {'matches': 13, 'total': 13}, u'RBS': {'matches': 1, 'total': 1}, u'CD': {'matches': 78, 'total': 79}, u'VP': {'matches': 119, 'total': 170}, u'S': {'matches': 110, 'total': 158}, u'EX': {'matches': 1, 'total': 1}, u'IN': {'matches': 101, 'total': 102}, u'CONJP': {'matches': 0, 'total': 2}, u'ADVP': {'matches': 7, 'total': 11}, u'QP': {'matches': 35, 'total': 46}, u'NNPS': {'matches': 6, 'total': 11}, u'JJS': {'matches': 3, 'total': 4}, u'JJR': {'matches': 5, 'total': 5}, u'WHNP': {'matches': 2, 'total': 5}}\n",
      "PRP$ --- total ------->  4\n",
      "PRP$ --- precision --->  1.0\n",
      "VBG --- total ------->  8\n",
      "VBG --- precision --->  0.5\n",
      "SBAR --- total ------->  24\n",
      "SBAR --- precision --->  0.666666666667\n",
      "VBD --- total ------->  48\n",
      "VBD --- precision --->  0.9375\n",
      "ADJP --- total ------->  31\n",
      "ADJP --- precision --->  0.516129032258\n",
      "`` --- total ------->  3\n",
      "`` --- precision --->  1.0\n",
      "VBN --- total ------->  23\n",
      "VBN --- precision --->  0.782608695652\n",
      "POS --- total ------->  19\n",
      "POS --- precision --->  1.0\n",
      "'' --- total ------->  3\n",
      "'' --- precision --->  1.0\n",
      "VBP --- total ------->  5\n",
      "VBP --- precision --->  0.8\n",
      "WDT --- total ------->  5\n",
      "WDT --- precision --->  0.4\n",
      "JJ --- total ------->  60\n",
      "JJ --- precision --->  0.866666666667\n",
      "VBZ --- total ------->  6\n",
      "VBZ --- precision --->  0.833333333333\n",
      "DT --- total ------->  68\n",
      "DT --- precision --->  1.0\n",
      "PP --- total ------->  109\n",
      "PP --- precision --->  0.660550458716\n",
      "RP --- total ------->  1\n",
      "RP --- precision --->  0.0\n",
      "$ --- total ------->  14\n",
      "$ --- precision --->  1.0\n",
      "NN --- total ------->  178\n",
      "NN --- precision --->  0.915730337079\n",
      ", --- total ------->  35\n",
      ", --- precision --->  1.0\n",
      ". --- total ------->  39\n",
      ". --- precision --->  1.0\n",
      "TO --- total ------->  25\n",
      "TO --- precision --->  1.0\n",
      "PRP --- total ------->  8\n",
      "PRP --- precision --->  1.0\n",
      "RB --- total ------->  28\n",
      "RB --- precision --->  0.892857142857\n",
      "NP --- total ------->  457\n",
      "NP --- precision --->  0.776805251641\n",
      ": --- total ------->  2\n",
      ": --- precision --->  1.0\n",
      "NNS --- total ------->  62\n",
      "NNS --- precision --->  0.774193548387\n",
      "NNP --- total ------->  72\n",
      "NNP --- precision --->  0.861111111111\n",
      "VB --- total ------->  16\n",
      "VB --- precision --->  0.9375\n",
      "MD --- total ------->  6\n",
      "MD --- precision --->  0.833333333333\n",
      "CC --- total ------->  13\n",
      "CC --- precision --->  1.0\n",
      "RBS --- total ------->  1\n",
      "RBS --- precision --->  1.0\n",
      "CD --- total ------->  79\n",
      "CD --- precision --->  0.987341772152\n",
      "VP --- total ------->  170\n",
      "VP --- precision --->  0.7\n",
      "S --- total ------->  158\n",
      "S --- precision --->  0.696202531646\n",
      "EX --- total ------->  1\n",
      "EX --- precision --->  1.0\n",
      "IN --- total ------->  102\n",
      "IN --- precision --->  0.990196078431\n",
      "CONJP --- total ------->  2\n",
      "CONJP --- precision --->  0.0\n",
      "ADVP --- total ------->  11\n",
      "ADVP --- precision --->  0.636363636364\n",
      "QP --- total ------->  46\n",
      "QP --- precision --->  0.760869565217\n",
      "NNPS --- total ------->  11\n",
      "NNPS --- precision --->  0.545454545455\n",
      "JJS --- total ------->  4\n",
      "JJS --- precision --->  0.75\n",
      "JJR --- total ------->  5\n",
      "JJR --- precision --->  1.0\n",
      "WHNP --- total ------->  5\n",
      "WHNP --- precision --->  0.4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{1: {'matches': 954, 'total': 954}, 2: {'matches': 195, 'total': 221}, 3: {'matches': 113, 'total': 137}, 4: {'matches': 67, 'total': 86}, 5: {'matches': 46, 'total': 64}, 6: {'matches': 31, 'total': 40}, 7: {'matches': 25, 'total': 38}, 8: {'matches': 17, 'total': 29}, 9: {'matches': 21, 'total': 29}, 10: {'matches': 18, 'total': 27}, 11: {'matches': 15, 'total': 22}, 12: {'matches': 13, 'total': 15}, 13: {'matches': 13, 'total': 20}, 14: {'matches': 10, 'total': 18}, 15: {'matches': 13, 'total': 18}, 16: {'matches': 11, 'total': 15}, 17: {'matches': 11, 'total': 14}, 18: {'matches': 12, 'total': 15}, 19: {'matches': 10, 'total': 11}, 20: {'matches': 9, 'total': 14}, 21: {'matches': 10, 'total': 13}, 22: {'matches': 10, 'total': 11}, 23: {'matches': 5, 'total': 7}, 24: {'matches': 5, 'total': 5}, 25: {'matches': 4, 'total': 4}, 26: {'matches': 2, 'total': 2}, 27: {'matches': 3, 'total': 3}, 28: {'matches': 4, 'total': 4}, 29: {'matches': 2, 'total': 3}, 30: {'matches': 2, 'total': 3}, 31: {'matches': 5, 'total': 5}, 32: {'matches': 3, 'total': 3}, 33: {'matches': 1, 'total': 2}, 34: {'matches': 1, 'total': 2}, 35: {'matches': 1, 'total': 2}, 36: {'matches': 3, 'total': 4}, 38: {'matches': 1, 'total': 1}, 39: {'matches': 1, 'total': 1}, 40: {'matches': 1, 'total': 1}}\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40]\n",
      "[1.0, 0.8823529411764706, 0.8248175182481752, 0.7790697674418605, 0.71875, 0.775, 0.6578947368421053, 0.5862068965517241, 0.7241379310344828, 0.6666666666666666, 0.6818181818181818, 0.8666666666666667, 0.65, 0.5555555555555556, 0.7222222222222222, 0.7333333333333333, 0.7857142857142857, 0.8, 0.9090909090909091, 0.6428571428571429, 0.7692307692307693, 0.9090909090909091, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.5, 0.5, 0.5, 0.75, 1.0, 1.0, 1.0]\n",
      "</pre><br/>\n",
      "<img src=\"./images/last_graph.png\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see a decline in accuracy (when labels are compared) as the length increases, with some outliers which can be easily explained by the test set size (there can only be so many constituents of length 20+ in 50 sentences, we could've gotten lucky).<br/>\n",
      "When only indices are tested the accuracy is pretty scattered, which could mean that:\n",
      "<ul>\n",
      "<li>our test set is again too small, or </li>\n",
      "<li>the metric is too weak, or </li>\n",
      "<li>simply that the parser was correct about indices more the higher we are in the tree (that makes sense too, S is always correct if we only check it covered (start,end) for only long constituents (=full sentence?).</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}