{
 "metadata": {
  "name": "",
  "signature": "sha256:31bba8e0bddb6bd238073d613b4075cead05d9f9533e457156a3988b04c7696d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Testing Norvig's Word Segmenter"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1) Define a method to turn Brown sentences into appropriate input for the segment2 function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segment2_format(sent):\n",
      "    return [word.lower().translate(TRANSLATION_TABLE) for word in sent]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2) Measure the accuracy of segment2 on the news category of the Brown corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "from wordSegment import segment2\n",
      "from testing_norvig import accuracy_of_segment2\n",
      "\n",
      "accuracy_of_segment2(segment2, brown.sents()[:150])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of segment2(): 0.89615354151650162\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Testing Norvig's Word Segmenter Dependency on the Language Model\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "import wordSegment_small\n",
      "from testing_norvig import write_models_to_files\n",
      "\n",
      "words = brown.words()[:1000000]\n",
      "write_models_to_files(words)\n",
      "\n",
      "print 'Testing Accuracy on *first* 150 sentences'\n",
      "accuracy_of_segment2(wordSegment_small.segment2, brown.sents()[:150])\n",
      "\n",
      "print 'Testing Accuracy on *last* 150 sentences'\n",
      "accuracy_of_segment2(wordSegment_small.segment2, brown.sents()[-150:])\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Answer: with smaller model (1,000,000 words, not all brown corpus) we got 0.92 accuracy\n",
      "when testing on first 150 sentences in brown.\n",
      "(This is cheating because our test & train data are the same).\n",
      "When testing on last 150 sentences in brown corpus the accuracy dropped to 0.66\n",
      "The original data files performed better on new data.\n",
      "Both original data and our data performed the same on learned brown data (but we cheated).\n",
      "(Or Maybe They also \"cheated\" and learned from brown...)\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Compiling a Hebrew Language Model\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1) Write a function getWords(w, t)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ALL_PREFIXES = [u'\u05d4', u'\u05d1', u'\u05db', u'\u05dc', u'\u05de', u'\u05de\u05db\u05e9' u'\u05de\u05d1', u'\u05d1\u05db\u05e9',  u'\u05d5', u'\u05db\u05e9',u'\u05de\u05e9', u'\u05dc\u05db\u05e9', u'\u05e9']\n",
      "\n",
      "PREFIXES = {\n",
      "    'DEF': [u'\u05d4'],\n",
      "    'PREPOSITION': [u'\u05d1', u'\u05db', u'\u05dc', u'\u05de', u'\u05de\u05db\u05e9' u'\u05de\u05d1', u'\u05d1\u05db\u05e9'],\n",
      "    'CONJ': [u'\u05d5'],\n",
      "    'TEMP': [u'\u05db\u05e9', u'\u05de\u05e9', u'\u05dc\u05db\u05e9'],\n",
      "    'REL': [u'\u05e9']\n",
      "}\n",
      "\n",
      "#Sort them by length\n",
      "ALL_PREFIXES.sort(key=len, reverse=True)\n",
      "for k in PREFIXES:\n",
      "    PREFIXES[k].sort(key=len, reverse=True)\n",
      "\n",
      "def getWords(word, tag):\n",
      "\n",
      "    prefix_tags = tag.getBguTag()[0]\n",
      "    word_index = 0\n",
      "    result = [] # (prefix_index, prefix len)\n",
      "\n",
      "    for prefix_tag, x in prefix_tags:\n",
      "        # print prefix_tag\n",
      "\n",
      "        if prefix_tag in PREFIXES:\n",
      "            possible_prefixes = PREFIXES[prefix_tag] + ALL_PREFIXES\n",
      "        else:\n",
      "            possible_prefixes = ALL_PREFIXES\n",
      "\n",
      "        if prefix_tag == 'DEF' and word[word_index] != PREFIXES['DEF'][0]:\n",
      "            # print 'Special Case. Invisible \"Ha\"'\n",
      "            result.append(PREFIXES['DEF'][0])\n",
      "            continue\n",
      "\n",
      "        for prefix in possible_prefixes:\n",
      "            if word[word_index:].startswith(prefix):\n",
      "                # print 'FOUND!!'\n",
      "                result.append(word[word_index:len(prefix)])\n",
      "                word_index += len(prefix)\n",
      "                # print prefix\n",
      "                break\n",
      "\n",
      "    result.append(word[word_index:])\n",
      "\n",
      "    return result\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "2) Build hebrew model files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from BguCorpusReader import BguCorpusReader\n",
      "from hebrew import build_hebrew_models\n",
      "\n",
      "c = BguCorpusReader()\n",
      "tagged_words = c.tagged_words()\n",
      "\n",
      "build_hebrew_models(tagged_words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building new models\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3) Test Accuracy of segment2 on new files created"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from hebrew import get_hebrew_sentences\n",
      "from testing_norvig import accuracy_of_segment2\n",
      "import wordSegment_hebrew\n",
      "\n",
      "print 'Calculating Accuracy *without* aggregation..'\n",
      "accuracy_of_segment2(wordSegment_hebrew.segment2, get_hebrew_sentences(tagged_words, 200))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calculating Accuracy *without* aggregation..\n",
        "Accuracy of segment2(): 0.46316317148594027\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "7) Derive a function from segment2 that will only segment real Hebrew tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segment2_hebrew(sents_no_spaces):\n",
      "    res = wordSegment_hebrew.segment2(sents_no_spaces)[1]\n",
      "    output = []\n",
      "    orig_index = 0\n",
      "    while orig_index < len(res)-2:\n",
      "        word = res[orig_index]\n",
      "        while res[orig_index] in ALL_PREFIXES and orig_index < len(res)-2:\n",
      "            word += res[orig_index+1]\n",
      "            orig_index += 1\n",
      "\n",
      "        output.append(word)\n",
      "        orig_index += 1\n",
      "\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "8) Evaluate the accuracy of this word segmenter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from testing_norvig import accuracy_of_segment2_hebrew\n",
      "\n",
      "print 'Calculating Accuracy *with* aggregation..'\n",
      "accuracy_of_segment2_hebrew(segment2_hebrew, get_hebrew_sentences(tagged_words, 200))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calculating Accuracy *with* aggregation..\n",
        "Accuracy of segment2(): 0.73102469880652843\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}