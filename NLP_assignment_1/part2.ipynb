{
 "metadata": {
  "signature": "sha256:9ee677ebadf5e0666efc10fac3837265c8493e71b126e74c48b2072546dd19c0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src.part2 import *\n",
      "from nltk import UnigramTagger\n",
      "\n",
      "all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "ds_length = len(all_words)\n",
      "train = all_words[int(0.2 * ds_length):]\n",
      "dev = all_words[:int(0.1 * ds_length)]\n",
      "test = all_words[int(0.1 * ds_length):int(0.2 * ds_length)]\n",
      "\n",
      "our_tagger = SimpleUnigramTagger(train=train)\n",
      "nltk_tagger = UnigramTagger(train=train)\n",
      "\n",
      "print our_tagger.evaluate(test)\n",
      "print nltk_tagger.evaluate(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the above code takes a long time, results:\n",
      "building our tagger took  0:00:13.400085\n",
      "building nltk tagger took  0:00:20.180736\n",
      "0.908655550217\n",
      "0.908655550217"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Filtering Entropy Affix Tagger"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Does entropy filtering improve accuracy?\n",
      "that depends on the way we measure accuracy. if we consider None as a mistake when calculating accuracy rate, using Entropy gives no adventage, because avoiding the mistakes caused by high entropy resulted in more 'None's, which are consdiered as bad.\n",
      "However, in a real environement where the tagger is part of a backoff or a voting strategy, entropy can be useful.\n",
      "For example FilteringExtripyAffixTageer with UnigramTagger as backoff will yield higher accuracy that AffixTagger with UnigramTagger as backoff tagger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "ds_length = len(all_words)\n",
      "train = all_words[int(0.2 * ds_length):]\n",
      "dev = all_words[:int(0.1 * ds_length)]\n",
      "test = all_words[int(0.1 * ds_length):int(0.2 * ds_length)]\n",
      "from nltk.tag import UnigramTagger\n",
      "cutoffs = range(0, 15)\n",
      "cutoffs = [x*0.1 for x in cutoffs]\n",
      "u0 = UnigramTagger(train)\n",
      "nt = AffixTagger(train=train, backoff=u0)\n",
      "\n",
      "print \"result of evaluating nltk affix tagger: \", nt.evaluate(test)\n",
      "print \"finding best cutoff\"\n",
      "for cutoff in cutoffs:\n",
      "    print \"cutoff: \", cutoff\n",
      "    eat = EntropyAffixTagger(train=train, cutoff=cutoff, backoff=u0)\n",
      "    print \"evaluating entropy affix tagger: \", eat.evaluate(dev)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We had following results:\n",
      "result of evaluating nltk affix tagger:  0.87488874361\n",
      "finding best cutoff\n",
      "cutoff:  0.0\n",
      "evaluating entropy affix tagger:  0.905657166474\n",
      "cutoff:  0.1\n",
      "evaluating entropy affix tagger:  0.909708997496\n",
      "cutoff:  0.2\n",
      "evaluating entropy affix tagger:  0.914020145704\n",
      "cutoff:  0.3\n",
      "evaluating entropy affix tagger:  0.916378311359\n",
      "cutoff:  0.4\n",
      "evaluating entropy affix tagger:  0.91796662912\n",
      "cutoff:  0.5\n",
      "evaluating entropy affix tagger:  0.918590611097\n",
      "cutoff:  0.6\n",
      "evaluating entropy affix tagger:  0.917585757004\n",
      "cutoff:  0.7\n",
      "evaluating entropy affix tagger:  0.916021750229\n",
      "cutoff:  0.8\n",
      "evaluating entropy affix tagger:  0.913614962602\n",
      "cutoff:  0.9\n",
      "evaluating entropy affix tagger:  0.907845155226\n",
      "cutoff:  1.0\n",
      "evaluating entropy affix tagger:  0.902853299406\n",
      "cutoff:  1.1\n",
      "evaluating entropy affix tagger:  0.899563212616\n",
      "cutoff:  1.2\n",
      "evaluating entropy affix tagger:  0.895876046385\n",
      "cutoff:  1.3\n",
      "evaluating entropy affix tagger:  0.89014675732\n",
      "cutoff:  1.4\n",
      "evaluating entropy affix tagger:  0.888979829985\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we can see that the higher the cutoff the closer our results are to the results of the normal AffixTagger which doesn't filter out anything. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from src.part2 import *\n",
      "from nltk import UnigramTagger\n",
      "\n",
      "all_words = corpus.brown.tagged_sents(tagset='universal')\n",
      "ds_length = len(all_words)\n",
      "train = all_words[int(0.2 * ds_length):]\n",
      "dev = all_words[:int(0.1 * ds_length)]\n",
      "test = all_words[int(0.1 * ds_length):int(0.2 * ds_length)]\n",
      "\n",
      "u0 = UnigramTagger(train)\n",
      "\n",
      "eat = EntropyAffixTagger(train=train, cutoff=0.5, backoff=u0)\n",
      "print \"evaluating entropy affix tagger: \", eat.evaluate(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "evaluating entropy affix tagger:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.922408021487\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result we get is:\n",
      "    evaluating entropy affix tagger:  0.922408021487\n",
      "When we run Entropy tagger with best cutoff on test, we get much better results than Affix tagger"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "2. how do you determine the range of values to test for the cutoff?\n",
      "Empirically by looking at possible values for the entroy. we know 0 is the minimum, and we saw the max is around 1.5.\n",
      "3. is the accuracy value evolving in a predictable manner as the cutoff varies?\n",
      "Yes - as seen above. \n",
      "4. describe the list of suffixes that are good tag predictors -- are you surprised by what you observe?\n",
      "in the list we observed both reasonable suffixes (like 'gly', 'sly' and the rest of the 'ly's) and semingly random ones (like 'wda'). This is what we exepcted - that's what happens in the normal affix tagger."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Entropy Voting"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The entropy voting tagger scored:\n",
      "    0.882371474255\n",
      "while running Unigram with Affix backoff scored:\n",
      "    0.938397435393\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}